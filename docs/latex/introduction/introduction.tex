
\chapter{Introduction}
\label{chap:introduction}

\begin{quote}
    ``We don't tell [computers] what to do, we give them examples... The problem is, sometimes we don't understand how it figured it out.``\\
    \vspace{0.5em} 
    \hfill -- Jeff Dean, Head of Google AI \cite{Dean2017BlackBox}
\end{quote}

Neural networks (NNs) have become a foundational technology in modern artificial intelligence, yet their widespread use has revealed important limitations. Among the most significant are their lack of explainability—the ``black-box`` effect—and the high computational cost of training. With platforms like Hugging Face and GitHub now hosting over a million pre-trained models \cite{huggingface2024review}, these challenges have drawn increasing attention. Motivated by this abundance of models, a new research direction—\textbf{weight space learning}—has emerged as a promising approach to better understand these limitations.

Formally, the weight space of a neural network refers to the set of all possible configurations of its parameters \( W \in \mathbb{R}^n \), where \( n \) is the total number of trainable weights. Each point in this space represents a unique model with a distinct mapping from inputs to outputs. Weight space learning thus concerns learning representations or distributions over this space, capturing how variations in \( W \) relate to model behaviour and how variations in model training influence \( W \). The field generally considers two types of tasks: discriminative and generative.

Discriminative weight space learning aims to extract meaningful information from pre-trained network weights. Embeddings of model weights are typically evaluated through tasks that predict meta-information about the original models, such as final performance or generalisation behaviour. These tasks demonstrate that weight embeddings capture informative aspects of the training process, providing both a measure of representation quality and practical predictive insights.

Generative weight space learning, by contrast, focuses on modelling the distribution of neural network weights \( P(W \mid \dots) \) to enable the synthesis of new models. Early approaches \cite{schurholt2022hyperrepresentationsgenerativemodelssampling, pmlr-v235-schurholt24a} employ autoencoders to learn compact latent representations of model zoos, facilitating the generation of novel weight configurations. Subsequent work \cite{bedionita2025instructionguidedautoregressiveneuralnetwork},\cite{meynent2025structureenoughleveragingbehavior} has explored conditioning these distributions on additional information, such as the dataset a model was trained on or its resulting performance, enabling the generation of weights tailored to specific tasks or behaviour patterns.

Although these approaches have advanced the field significantly, they typically focus on isolated aspects of weight learning. Current methods address either dataset-conditioned or performance-conditioned distributions, but rarely both simultaneously. This separation overlooks the fact that a model's weights are shaped by both the data it is trained on and the results it achieves. Capturing the joint relationship \( P(W \mid \mathcal{D}, R) \) is therefore critical for fully understanding model behaviour and for generating models with specific, desired characteristics.

% In discriminative applications, pre-trained model weights are used to predict meta-information about the original models. Weight space representations are typically evaluated by the performance of a simple MLP in predicting this meta-information from the embeddings, using metrics such as final model performance or generalisation gap \cite{unterthiner2021predictingneuralnetworkaccuracy}. These discriminative tasks show that weight embeddings capture key training characteristics, providing both a measure of representation quality and practical predictive insights.

% Recent research in generative weight modelling focuses on learning the distribution of neural network weights \( P(W \mid \dots) \) to enable the generation of new models. 
% \cite{schurholt2022hyperrepresentationsgenerativemodelssampling} , \cite{pmlr-v235-schurholt24a} learn compact representations of model zoos through autoencoders, allowing for generation of new model weights. 

% Other approaches focus on conditioning the weight distribution on the dataset \( \mathcal{D} \) the model is trained on or resulting performance \( R \). \cite{bedionita2025instructionguidedautoregressiveneuralnetwork} employed a Vector Quantised Variational Autoencoder (VQ-VAE) to model \( P(W \mid \mathcal{D}) \) by encoding dataset-dependent weight structures, while \cite{meynent2025structureenoughleveragingbehavior} modelled \( P(W \mid R) \) by incorporating behavioural differences between original and reconstructed models.

% While existing weight space learning methods have made significant progress, they typically address isolated aspects of the learning process. Current approaches model either \( P(W \mid \mathcal{D}) \) or \( P(W \mid R) \), but never both simultaneously. This separation overlooks the fact that a model's weights are defined by both the data it is trained on and the performance it achieves. Capturing the joint relationship \( P(W \mid \mathcal{D}, R) \) is therefore crucial for understanding model behaviour and for generating models with specific, desired characteristics.

Contrastive learning has emerged as a powerful paradigm for learning unified representations across modalities, as demonstrated by models such as CLIP \cite{pmlr-v139-radford21a}, which align vision and language in a shared representation space. A contrastive objective pulls related samples closer in representation space while pushing unrelated samples apart, creating a meaningful joint embedding space for heterogeneous data types. This property makes contrastive learning particularly suitable for modelling the complex distribution \( P(W \mid \mathcal{D}, R) \) , as it can embed multiple, fundamentally different data modalities into a common space without requiring them to share the same input dimensionality or structure.

\begin{figure}[!t]
    \centering
    \includegraphics[width=0.75\linewidth]{pipeline.png}
    \caption[A Conditonal Model Sampling system,  embedding a dataset, model weights and results into a shared embedding space.]{A Conditonal Model Sampling system,  embedding a dataset, model weights and results into a shared embedding space}
    \label{fig:pipeline}
\end{figure}

In this report, we propose a contrastive learning framework to create a unified embedding space that jointly represents neural network weights , the datasets they were trained on, and their resulting performance characteristics. Specifically, we construct two separate encoders—one for dataset embeddings using pre-trained CLIP features, and another for weight embeddings using an autoencoder architecture—alongside a binned result embedding table. These encoders are trained using the contrastive objective NT-Xent \cite{pmlr-v119-chen20j}, which encourages related triplets \( (\mathcal{D}, W, R) \) to be close in the shared embedding space. Figure \ref{fig:pipeline} depicts a high-level view of the full embedding pipeline.

Our central hypothesis is that this unified representation space will enable two key capabilities:

\begin{itemize}
    \item \textbf{Interpretability and Analysis:} Examining geometric relationships within the shared embedding space can reveal how dataset characteristics shape learned weights and model behaviour.
    \item \textbf{Conditional Model Sampling:} The learned distribution enables sampling of model weights conditioned on both dataset properties and target performance metrics--approximating \( P(W \mid \mathcal{D}, R) \).
\end{itemize}

The primary goal of this report is to demonstrate the viability of our methodology through successful conditional model sampling. While our hypothesis addresses both interpretability and conditional model generation, success in the latter provides strong evidence for the former. Specifically, the ability to accurately sample weights that achieve target performance metrics, conditioned on specific dataset and result targets, indicates that the unified embedding space has effectively captured the complex relationship between \((\mathcal{D},R)\), and \(W\). Accordingly, this report focuses on generating meaningful representations, evaluating their quality, and performing conditional model sampling to assess the effectiveness of the proposed methodology for generative weight space modelling.
