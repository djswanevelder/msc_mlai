@inproceedings{
      bedionita2025instructionguidedautoregressiveneuralnetwork,
      title={Instruction-Guided Autoregressive Neural Network Parameter Generation},
      author={Bedionita Soro and Bruno Andreis and Song Chong and Sung Ju Hwang},
      booktitle={Workshop on Neural Network Weights as a New Data Modality},
      year={2025},
      url={https://openreview.net/forum?id=QutFK34ea1}
}
@misc{salama2024datasetsizerecoverylora,
      title={Dataset Size Recovery from LoRA Weights}, 
      author={Mohammad Salama and Jonathan Kahana and Eliahu Horwitz and Yedid Hoshen},
      year={2024},
      eprint={2406.19395},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.19395}, 
}
@inproceedings{
      meynent2025structureenoughleveragingbehavior,
      title={Structure Is Not Enough: Leveraging Behavior for Neural Network Weight Reconstruction},
      author={L{\'e}o Meynent and Ivan Melev and Konstantin Sch{\"u}rholt and Goeran Kauermann and Damian Borth},
      booktitle={Workshop on Neural Network Weights as a New Data Modality},
      year={2025},
      url={https://openreview.net/forum?id=APsHrpqO3W}
      }
@inproceedings{NEURIPS2022_b2c4b7d3,
 author = {Sch\"{u}rholt, Konstantin and Knyazev, Boris and Gir\'{o}-i-Nieto, Xavier and Borth, Damian},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {27906--27920},
 publisher = {Curran Associates, Inc.},
 title = {Hyper-Representations as Generative Models: Sampling Unseen Neural Network Weights},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/b2c4b7d34b3d96b9dc12f7bce424b7ae-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}
@inproceedings{pmlr-v235-schurholt24a,
    title={Towards Scalable and Versatile Weight Space Learning},
    author={Konstantin Sch{\"u}rholt and Michael W. Mahoney and Damian Borth},
    booktitle={Proceedings of the 41st International Conference on Machine Learning (ICML)},
    year={2024},
    organization={PMLR}
}

@misc{Dean2017BlackBox,
author = {Dean, Jeff},
title = {Keynote Speech on the Future of AI},
booktitle = {Google I/O Conference},
year = {2017},
note = {Statement widely attributed to the keynote speech, highlighting the challenge of interpretability in deep learning systems.},
howpublished = {\url{https://www.google.com/search?q=https://events.google.com/io/}}
}

@misc{huggingface2024review,
  title = {{Open-source AI: Year in Review 2024}},
  author = {{Hugging Face}},
  year = {2024},
  howpublished = {\url{https://huggingface.co/spaces/huggingface/open-source-ai-year-in-review-2024}},
  note = {Accessed: 14 October 2025}
}
@inproceedings{
      schurholt2022modelzoosdatasetdiverse,
      title={Model Zoos: A Dataset of Diverse Populations of Neural Network Models},
      author={Konstantin Sch{\"u}rholt and Diyar Taskiran and Boris Knyazev and Xavier Gir{\'o}-i-Nieto and Damian Borth},
      booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
      year={2022},
      url={https://openreview.net/forum?id=MOCZI3h8Ye}
}

@misc{unterthiner2021predictingneuralnetworkaccuracy,
      title={Predicting Neural Network Accuracy from Weights}, 
      author={Thomas Unterthiner and Daniel Keysers and Sylvain Gelly and Olivier Bousquet and Ilya Tolstikhin},
      year={2021},
      eprint={2002.11448},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2002.11448}, 
}

@misc{schurholt2022hyperrepresentationsgenerativemodelssampling,
      title={Hyper-Representations as Generative Models: Sampling Unseen Neural Network Weights}, 
      author={Konstantin Schürholt and Boris Knyazev and Xavier Giró-i-Nieto and Damian Borth},
      year={2022},
      eprint={2209.14733},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2209.14733}, 
}

@InProceedings{radford2021learningtransferablevisualmodels,
  title = 	 {Learning Transferable Visual Models From Natural Language Supervision},
  author =       {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {8748--8763},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/radford21a/radford21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/radford21a.html},
}

@misc{agren2022ntxentlossupperbound,
      title={The NT-Xent loss upper bound}, 
      author={Wilhelm Ågren},
      year={2022},
      eprint={2205.03169},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2205.03169}, 
}