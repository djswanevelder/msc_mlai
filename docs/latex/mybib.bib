@inproceedings{
      bedionita2025instructionguidedautoregressiveneuralnetwork,
      title={Instruction-Guided Autoregressive Neural Network Parameter Generation},
      author={Bedionita Soro and Bruno Andreis and Song Chong and Sung Ju Hwang},
      booktitle={Workshop on Neural Network Weights as a New Data Modality},
      year={2025},
      url={https://openreview.net/forum?id=QutFK34ea1}
}
@misc{salama2024datasetsizerecoverylora,
      title={Dataset Size Recovery from LoRA Weights}, 
      author={Mohammad Salama and Jonathan Kahana and Eliahu Horwitz and Yedid Hoshen},
      year={2024},
      eprint={2406.19395},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.19395}, 
}
@inproceedings{
      meynent2025structureenoughleveragingbehavior,
      title={Structure Is Not Enough: Leveraging Behavior for Neural Network Weight Reconstruction},
      author={L{\'e}o Meynent and Ivan Melev and Konstantin Sch{\"u}rholt and Goeran Kauermann and Damian Borth},
      booktitle={Workshop on Neural Network Weights as a New Data Modality},
      year={2025},
      url={https://openreview.net/forum?id=APsHrpqO3W}
      }
@inproceedings{NEURIPS2022_b2c4b7d3,
 author = {Sch\"{u}rholt, Konstantin and Knyazev, Boris and Gir\'{o}-i-Nieto, Xavier and Borth, Damian},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {27906--27920},
 publisher = {Curran Associates, Inc.},
 title = {Hyper-Representations as Generative Models: Sampling Unseen Neural Network Weights},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/b2c4b7d34b3d96b9dc12f7bce424b7ae-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}
@inproceedings{pmlr-v235-schurholt24a,
    title={Towards Scalable and Versatile Weight Space Learning},
    author={Konstantin Sch{\"u}rholt and Michael W. Mahoney and Damian Borth},
    booktitle={Proceedings of the 41st International Conference on Machine Learning (ICML)},
    year={2024},
    organization={PMLR}
}

@misc{Dean2017BlackBox,
author = {Dean, Jeff},
title = {Keynote Speech on the Future of AI},
booktitle = {Google I/O Conference},
year = {2017},
note = {Statement widely attributed to the keynote speech, highlighting the challenge of interpretability in deep learning systems.},
howpublished = {\url{https://www.google.com/search?q=https://events.google.com/io/}}
}

@misc{huggingface2024review,
  title = {{Open-source AI: Year in Review 2024}},
  author = {{Hugging Face}},
  year = {2024},
  howpublished = {\url{https://huggingface.co/spaces/huggingface/open-source-ai-year-in-review-2024}},
  note = {Accessed: 14 October 2025}
}
@inproceedings{
      schurholt2022modelzoosdatasetdiverse,
      title={Model Zoos: A Dataset of Diverse Populations of Neural Network Models},
      author={Konstantin Sch{\"u}rholt and Diyar Taskiran and Boris Knyazev and Xavier Gir{\'o}-i-Nieto and Damian Borth},
      booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
      year={2022},
      url={https://openreview.net/forum?id=MOCZI3h8Ye}
}

@misc{unterthiner2021predictingneuralnetworkaccuracy,
      title={Predicting Neural Network Accuracy from Weights}, 
      author={Thomas Unterthiner and Daniel Keysers and Sylvain Gelly and Olivier Bousquet and Ilya Tolstikhin},
      year={2021},
      eprint={2002.11448},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2002.11448}, 
}

@misc{schurholt2022hyperrepresentationsgenerativemodelssampling,
      title={Hyper-Representations as Generative Models: Sampling Unseen Neural Network Weights}, 
      author={Konstantin Schürholt and Boris Knyazev and Xavier Giró-i-Nieto and Damian Borth},
      year={2022},
      eprint={2209.14733},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2209.14733}, 
}

@InProceedings{radford2021learningtransferablevisualmodels,
  title = 	 {Learning Transferable Visual Models From Natural Language Supervision},
  author =       {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {8748--8763},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/radford21a/radford21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/radford21a.html},
}

@misc{agren2022ntxentlossupperbound,
      title={The NT-Xent loss upper bound}, 
      author={Wilhelm Ågren},
      year={2022},
      eprint={2205.03169},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2205.03169}, 
}

@book{foundationsCVbook,
  title={Foundations of Computer Vision},
  author={Torralba, A. and Isola, P. and Freeman, W.T.},
  isbn={9780262378666},
  lccn={2023024589},
  series={Adaptive Computation and Machine Learning series},
  url={https://mitpress.mit.edu/9780262048972/foundations-of-computer-vision/},
  year={2024},
  publisher={MIT Press}
}

@InProceedings{pmlr-v139-radford21a,
  title = 	 {Learning Transferable Visual Models From Natural Language Supervision},
  author =       {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {8748--8763},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/radford21a/radford21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/radford21a.html},
  abstract = 	 {State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on.}
}


@CONFERENCE{ImageNet_VSS09,
        AUTHOR = {Deng, J. and Li, K. and Do, M. and Su, H. and Fei-Fei, L.},        
        TITLE = {{Construction and Analysis of a Large Scale Image Ontology}},
        ORGANIZATION = {Vision Sciences Society},
        YEAR = {2009},
        BIBSOURCE = "http://www.image-net.org/papers/ImageNet_VSS2009.bib"}

@article{He2015DeepRL,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and X. Zhang and Shaoqing Ren and Jian Sun},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2015},
  pages={770-778},
  url={https://api.semanticscholar.org/CorpusID:206594692}
}