% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Dean2017BlackBox}
J.~Dean, ``Keynote speech on the future of ai,''
  \url{https://www.google.com/search?q=https://events.google.com/io/}, 2017,
  statement widely attributed to the keynote speech, highlighting the challenge
  of interpretability in deep learning systems.

\bibitem{huggingface2024review}
{Hugging Face}, ``{Open-source AI: Year in Review 2024},''
  \url{https://huggingface.co/spaces/huggingface/open-source-ai-year-in-review-2024},
  2024, accessed: 14 October 2025.

\bibitem{schurholt2022hyperrepresentationsgenerativemodelssampling}
\BIBentryALTinterwordspacing
K.~Schürholt, B.~Knyazev, X.~G. i~Nieto, and D.~Borth, ``Hyper-representations
  as generative models: Sampling unseen neural network weights,'' 2022.
  [Online]. Available: \url{https://arxiv.org/abs/2209.14733}
\BIBentrySTDinterwordspacing

\bibitem{pmlr-v235-schurholt24a}
K.~Sch{\"u}rholt, M.~W. Mahoney, and D.~Borth, ``Towards scalable and versatile
  weight space learning,'' in \emph{Proceedings of the 41st International
  Conference on Machine Learning (ICML)}.\hskip 1em plus 0.5em minus
  0.4em\relax PMLR, 2024.

\bibitem{bedionita2025instructionguidedautoregressiveneuralnetwork}
\BIBentryALTinterwordspacing
B.~Soro, B.~Andreis, S.~Chong, and S.~J. Hwang, ``Instruction-guided
  autoregressive neural network parameter generation,'' in \emph{Workshop on
  Neural Network Weights as a New Data Modality}, 2025. [Online]. Available:
  \url{https://openreview.net/forum?id=QutFK34ea1}
\BIBentrySTDinterwordspacing

\bibitem{meynent2025structureenoughleveragingbehavior}
\BIBentryALTinterwordspacing
L.~Meynent, I.~Melev, K.~Sch{\"u}rholt, G.~Kauermann, and D.~Borth, ``Structure
  is not enough: Leveraging behavior for neural network weight
  reconstruction,'' in \emph{Workshop on Neural Network Weights as a New Data
  Modality}, 2025. [Online]. Available:
  \url{https://openreview.net/forum?id=APsHrpqO3W}
\BIBentrySTDinterwordspacing

\bibitem{pmlr-v139-radford21a}
\BIBentryALTinterwordspacing
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark, G.~Krueger, and I.~Sutskever, ``Learning
  transferable visual models from natural language supervision,'' in
  \emph{Proceedings of the 38th International Conference on Machine Learning},
  ser. Proceedings of Machine Learning Research, M.~Meila and T.~Zhang, Eds.,
  vol. 139.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 18--24 Jul 2021, pp.
  8748--8763. [Online]. Available:
  \url{https://proceedings.mlr.press/v139/radford21a.html}
\BIBentrySTDinterwordspacing

\bibitem{pmlr-v119-chen20j}
\BIBentryALTinterwordspacing
T.~Chen, S.~Kornblith, M.~Norouzi, and G.~Hinton, ``A simple framework for
  contrastive learning of visual representations,'' in \emph{Proceedings of the
  37th International Conference on Machine Learning}, ser. Proceedings of
  Machine Learning Research, H.~Daumé~III and A.~Singh, Eds., vol. 119.\hskip
  1em plus 0.5em minus 0.4em\relax PMLR, 13--18 Jul 2020, pp. 1597--1607.
  [Online]. Available: \url{https://proceedings.mlr.press/v119/chen20j.html}
\BIBentrySTDinterwordspacing

\bibitem{pmlr-v38-choromanska15}
\BIBentryALTinterwordspacing
A.~Choromanska, M.~Henaff, M.~Mathieu, G.~Ben~Arous, and Y.~LeCun, ``{The Loss
  Surfaces of Multilayer Networks},'' in \emph{Proceedings of the Eighteenth
  International Conference on Artificial Intelligence and Statistics}, ser.
  Proceedings of Machine Learning Research, G.~Lebanon and S.~V.~N.
  Vishwanathan, Eds., vol.~38.\hskip 1em plus 0.5em minus 0.4em\relax San
  Diego, California, USA: PMLR, 09--12 May 2015, pp. 192--204. [Online].
  Available: \url{https://proceedings.mlr.press/v38/choromanska15.html}
\BIBentrySTDinterwordspacing

\bibitem{schurholt2022modelzoosdatasetdiverse}
\BIBentryALTinterwordspacing
K.~Sch{\"u}rholt, D.~Taskiran, B.~Knyazev, X.~G. i~Nieto, and D.~Borth, ``Model
  zoos: A dataset of diverse populations of neural network models,'' in
  \emph{Thirty-sixth Conference on Neural Information Processing Systems
  Datasets and Benchmarks Track}, 2022. [Online]. Available:
  \url{https://openreview.net/forum?id=MOCZI3h8Ye}
\BIBentrySTDinterwordspacing

\bibitem{unterthiner2021predictingneuralnetworkaccuracy}
\BIBentryALTinterwordspacing
T.~Unterthiner, D.~Keysers, S.~Gelly, O.~Bousquet, and I.~Tolstikhin,
  ``Predicting neural network accuracy from weights,'' 2021. [Online].
  Available: \url{https://arxiv.org/abs/2002.11448}
\BIBentrySTDinterwordspacing

\bibitem{Hinton2006Reducing}
\BIBentryALTinterwordspacing
G.~E. Hinton and R.~R. Salakhutdinov, ``Reducing the dimensionality of data
  with neural networks,'' \emph{Science}, vol. 313, no. 5786, pp. 504--507,
  2006. [Online]. Available:
  \url{https://www.cs.toronto.edu/~hinton/absps/science.pdf}
\BIBentrySTDinterwordspacing

\bibitem{foundationsCVbook}
\BIBentryALTinterwordspacing
A.~Torralba, P.~Isola, and W.~Freeman, \emph{Foundations of Computer Vision},
  ser. Adaptive Computation and Machine Learning series.\hskip 1em plus 0.5em
  minus 0.4em\relax MIT Press, 2024. [Online]. Available:
  \url{https://mitpress.mit.edu/9780262048972/foundations-of-computer-vision/}
\BIBentrySTDinterwordspacing

\bibitem{NEURIPS2022_b2c4b7d3}
\BIBentryALTinterwordspacing
K.~Sch\"{u}rholt, B.~Knyazev, X.~Gir\'{o}-i Nieto, and D.~Borth,
  ``Hyper-representations as generative models: Sampling unseen neural network
  weights,'' in \emph{Advances in Neural Information Processing Systems},
  S.~Koyejo, S.~Mohamed, A.~Agarwal, D.~Belgrave, K.~Cho, and A.~Oh, Eds.,
  vol.~35.\hskip 1em plus 0.5em minus 0.4em\relax Curran Associates, Inc.,
  2022, pp. 27\,906--27\,920. [Online]. Available:
  \url{https://proceedings.neurips.cc/paper_files/paper/2022/file/b2c4b7d34b3d96b9dc12f7bce424b7ae-Paper-Conference.pdf}
\BIBentrySTDinterwordspacing

\bibitem{ImageNet_VSS09}
J.~Deng, K.~Li, M.~Do, H.~Su, and L.~Fei-Fei, ``{Construction and Analysis of a
  Large Scale Image Ontology}.''\hskip 1em plus 0.5em minus 0.4em\relax Vision
  Sciences Society, 2009.

\bibitem{He2015DeepRL}
\BIBentryALTinterwordspacing
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' \emph{2016 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp. 770--778, 2015. [Online]. Available:
  \url{https://api.semanticscholar.org/CorpusID:206594692}
\BIBentrySTDinterwordspacing

\bibitem{wang2020datasetdistillation}
\BIBentryALTinterwordspacing
T.~Wang, J.-Y. Zhu, A.~Torralba, and A.~A. Efros, ``Dataset distillation,''
  2020. [Online]. Available: \url{https://arxiv.org/abs/1811.10959}
\BIBentrySTDinterwordspacing

\end{thebibliography}
