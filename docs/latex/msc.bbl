% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Dean2017BlackBox}
J.~Dean, ``Keynote speech on the future of ai,''
  \url{https://www.google.com/search?q=https://events.google.com/io/}, 2017,
  statement widely attributed to the keynote speech, highlighting the challenge
  of interpretability in deep learning systems.

\bibitem{huggingface2024review}
{Hugging Face}, ``{Open-source AI: Year in Review 2024},''
  \url{https://huggingface.co/spaces/huggingface/open-source-ai-year-in-review-2024},
  2024, accessed: 14 October 2025.

\bibitem{schurholt2022modelzoosdatasetdiverse}
\BIBentryALTinterwordspacing
K.~Sch{\"u}rholt, D.~Taskiran, B.~Knyazev, X.~G. i~Nieto, and D.~Borth, ``Model
  zoos: A dataset of diverse populations of neural network models,'' in
  \emph{Thirty-sixth Conference on Neural Information Processing Systems
  Datasets and Benchmarks Track}, 2022. [Online]. Available:
  \url{https://openreview.net/forum?id=MOCZI3h8Ye}
\BIBentrySTDinterwordspacing

\bibitem{unterthiner2021predictingneuralnetworkaccuracy}
\BIBentryALTinterwordspacing
T.~Unterthiner, D.~Keysers, S.~Gelly, O.~Bousquet, and I.~Tolstikhin,
  ``Predicting neural network accuracy from weights,'' 2021. [Online].
  Available: \url{https://arxiv.org/abs/2002.11448}
\BIBentrySTDinterwordspacing

\bibitem{salama2024datasetsizerecoverylora}
\BIBentryALTinterwordspacing
M.~Salama, J.~Kahana, E.~Horwitz, and Y.~Hoshen, ``Dataset size recovery from
  lora weights,'' 2024. [Online]. Available:
  \url{https://arxiv.org/abs/2406.19395}
\BIBentrySTDinterwordspacing

\bibitem{schurholt2022hyperrepresentationsgenerativemodelssampling}
\BIBentryALTinterwordspacing
K.~Schürholt, B.~Knyazev, X.~G. i~Nieto, and D.~Borth, ``Hyper-representations
  as generative models: Sampling unseen neural network weights,'' 2022.
  [Online]. Available: \url{https://arxiv.org/abs/2209.14733}
\BIBentrySTDinterwordspacing

\bibitem{pmlr-v235-schurholt24a}
K.~Sch{\"u}rholt, M.~W. Mahoney, and D.~Borth, ``Towards scalable and versatile
  weight space learning,'' in \emph{Proceedings of the 41st International
  Conference on Machine Learning (ICML)}.\hskip 1em plus 0.5em minus
  0.4em\relax PMLR, 2024.

\bibitem{bedionita2025instructionguidedautoregressiveneuralnetwork}
\BIBentryALTinterwordspacing
B.~Soro, B.~Andreis, S.~Chong, and S.~J. Hwang, ``Instruction-guided
  autoregressive neural network parameter generation,'' in \emph{Workshop on
  Neural Network Weights as a New Data Modality}, 2025. [Online]. Available:
  \url{https://openreview.net/forum?id=QutFK34ea1}
\BIBentrySTDinterwordspacing

\bibitem{meynent2025structureenoughleveragingbehavior}
\BIBentryALTinterwordspacing
L.~Meynent, I.~Melev, K.~Sch{\"u}rholt, G.~Kauermann, and D.~Borth, ``Structure
  is not enough: Leveraging behavior for neural network weight
  reconstruction,'' in \emph{Workshop on Neural Network Weights as a New Data
  Modality}, 2025. [Online]. Available:
  \url{https://openreview.net/forum?id=APsHrpqO3W}
\BIBentrySTDinterwordspacing

\bibitem{radford2021learningtransferablevisualmodels}
\BIBentryALTinterwordspacing
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark, G.~Krueger, and I.~Sutskever, ``Learning
  transferable visual models from natural language supervision,'' in
  \emph{Proceedings of the 38th International Conference on Machine Learning},
  ser. Proceedings of Machine Learning Research, M.~Meila and T.~Zhang, Eds.,
  vol. 139.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 18--24 Jul 2021, pp.
  8748--8763. [Online]. Available:
  \url{https://proceedings.mlr.press/v139/radford21a.html}
\BIBentrySTDinterwordspacing

\bibitem{agren2022ntxentlossupperbound}
\BIBentryALTinterwordspacing
W.~Ågren, ``The nt-xent loss upper bound,'' 2022. [Online]. Available:
  \url{https://arxiv.org/abs/2205.03169}
\BIBentrySTDinterwordspacing

\bibitem{NEURIPS2022_b2c4b7d3}
\BIBentryALTinterwordspacing
K.~Sch\"{u}rholt, B.~Knyazev, X.~Gir\'{o}-i Nieto, and D.~Borth,
  ``Hyper-representations as generative models: Sampling unseen neural network
  weights,'' in \emph{Advances in Neural Information Processing Systems},
  S.~Koyejo, S.~Mohamed, A.~Agarwal, D.~Belgrave, K.~Cho, and A.~Oh, Eds.,
  vol.~35.\hskip 1em plus 0.5em minus 0.4em\relax Curran Associates, Inc.,
  2022, pp. 27\,906--27\,920. [Online]. Available:
  \url{https://proceedings.neurips.cc/paper_files/paper/2022/file/b2c4b7d34b3d96b9dc12f7bce424b7ae-Paper-Conference.pdf}
\BIBentrySTDinterwordspacing

\end{thebibliography}
